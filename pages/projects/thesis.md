::: article
::: paragraph
::: text
## Gaze + Pinch in Action

&nbsp;

The accommodating paper co-written with [Ken Pfeuffer](https://kenpfeuffer.com/) was published to the [ACM Digital Library](https://dl.acm.org/citation.cfm?id=3132180) for [the 5th ACM Symposium on Spatial User Interaction (SUI 2017)](http://www.sui2017.org/).  

&nbsp; 

You can find more publications of mine on [Google Scholar](https://scholar.google.de/citations?user=ZHmZq24AAAAJ&hl=en). There is also a [full talk about the Gaze+Pinch paper](https://www.youtube.com/watch?v=YdKT42tZdQE) given by my colleague Ken Pfeuffer at SUI 2017.
:::
::: image
::: video
<iframe src="https://www.youtube.com/embed/NzLrZSF8aDM" title="YouTube video of the Gaze+Pinch technique." frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
:::
:::
:::
::: paragraph


::: image
![Basic 3D interaction with gaze + pinch to manipulate cubes in a VR setting.](../static/img/thesis.jpg) \

::: caption
Basic 3D interaction with gaze + pinch.
::: 
:::

::: text
## Eye-Tracking and Gestures in VR

&nbsp;

In my bachelor thesis we proposed a new interaction technique integrating manual interaction and eye-tracking into VR, called gaze + pinch.  

&nbsp; 

Non-VR 3D interaction techniques have had many recent approaches using manual and gaze-based input which we propose could improve interaction in VR as well.  

&nbsp; 

Manual input appears particularly promising to solve problems of intuitiveness and immersion but lacks the ability to easily interact with remote objects, which eye-tracking tries to deal with.
::: 
:::
    
::: paragraph
::: text
## Immersive and Intuitive Interaction

&nbsp;

The current state of the art in VR interaction is controllers like the ones of the HTC Vive shown here.
But introducing foreign objects into a VR scene can break immersion, the most important property of any VR application.  

&nbsp; 

This is especially true for applications where the user wouldn't expect to hold something in their hands, like a social or climbing application.
:::

::: image
![HTC Vive headset and controllers. Image from ETC-USC on flickr https://www.flickr.com/photos/92587836@N04/24177102722/](../static/img/vive_controllers.jpg) \

::: caption
HTC Vive headset and controllers. Image from [ETC-USC on flickr](https://www.flickr.com/photos/92587836@N04/24177102722/).
:::
:::
:::

::: paragraph
::: image
![A 3D living room scene, showing eye gaze + hand pinching interaction in VR. The image shows a picture-in-picture view of the user in the top right.](../static/img/paper_livingroom.jpg) \

::: caption
In a 3D living room scene, the user can rearrange their furniture by using gaze + pinch.
::: 
:::

::: text
## Expanding the Concept

&nbsp;

Thus, we introduced a new concept combining the advantages of gesture interaction with those of eye tracking.  

&nbsp; 

One example application we built is a  living room scene, in which the user can use gaze + pinch to arrange their furniture to their liking.  

&nbsp; 

In this scene, we demonstrate how one can easily use eye gaze for selection (indicated by the grey circle) in combination with gesture interaction for positioning.
:::
:::
:::